{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"lmsys/chatbot_arena_conversations\")\n",
    "data = [x for x in dataset['train']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 29126,\n",
       "         4: 2557,\n",
       "         6: 785,\n",
       "         8: 289,\n",
       "         10: 108,\n",
       "         12: 56,\n",
       "         14: 31,\n",
       "         16: 18,\n",
       "         18: 13,\n",
       "         20: 8,\n",
       "         26: 2,\n",
       "         24: 2,\n",
       "         22: 2,\n",
       "         30: 1,\n",
       "         50: 1,\n",
       "         38: 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([len(x['conversation_a']) for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32757\n"
     ]
    }
   ],
   "source": [
    "# keep only conversations with 2 turns\n",
    "import json\n",
    "data = [x for x in data if len(x['conversation_a'])]\n",
    "new_data = []\n",
    "\n",
    "for i, x in enumerate(data):\n",
    "    new_item = {\n",
    "        \"id\": f\"chatbot_arena_conversations_{x['question_id']}\",\n",
    "        \"instruction\": \"Finish the following coversation in each i-th turn by filling in <Response i> with your response.\",\n",
    "        \"input\": \"\\n\".join([\n",
    "            \"USER: \" + x['conversation_a'][i]['content'] +\n",
    "            f\"\\nAssistant: <Response {i//2+1}>\" for i in range(0, len(x['conversation_a']), 2)\n",
    "        ]),\n",
    "        \"candidates\": [\n",
    "            {\n",
    "                \"text\": \"\\n\".join([\n",
    "                    f\"<Response {i//2+1}>: \" + x['conversation_a'][i]['content']\n",
    "                    for i in range(1, len(x['conversation_a']), 2)\n",
    "                ]),\n",
    "                \"model\": x['model_a'],\n",
    "                \"decoding_method\": \"unknown\",\n",
    "                \"scores\": {\n",
    "                    \"human_preference\": 1.0 if x['winner'] == 'model_a' else 0.0,\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"\\n\".join([\n",
    "                    f\"<Response {i//2+1}>: \" + x['conversation_b'][i]['content']\n",
    "                    for i in range(1, len(x['conversation_b']), 2)\n",
    "                ]),\n",
    "                \"model\": x['model_b'],\n",
    "                \"decoding_method\": \"unknown\",\n",
    "                \"scores\": {\n",
    "                    \"human_preference\": 1.0 if x['winner'] == 'model_b' else 0.0,\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    new_data.append(new_item)\n",
    "print(len(new_data))\n",
    "train_data = new_data[:int(len(new_data)*0.9)]\n",
    "val_data = new_data[int(len(new_data)*0.9):]\n",
    "with open(\"train_data_prepared.json\", \"w\") as f:\n",
    "    json.dump(train_data, f, indent=4, ensure_ascii=False)\n",
    "with open(\"val_data_prepared.json\", \"w\") as f:\n",
    "    json.dump(val_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29481/29481 [00:05<00:00, 5369.38it/s]\n",
      "100%|██████████| 29481/29481 [00:17<00:00, 1706.96it/s]\n",
      "100%|██████████| 29481/29481 [00:17<00:00, 1724.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"llm-blender/pair-ranker\")\n",
    "input_lens = [len(tokenizer.encode(x['input'])) for x in tqdm(train_data)]\n",
    "cand1_lens = [len(tokenizer.encode(x['candidates'][0]['text'])) for x in tqdm(train_data)]\n",
    "cand2_lens = [len(tokenizer.encode(x['candidates'][1]['text'])) for x in tqdm(train_data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533.4000000000015, 846.4000000000015, 845.4000000000015)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "percentage = 99\n",
    "np.percentile(input_lens, percentage), np.percentile(cand1_lens, percentage), np.percentile(cand2_lens, percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal 0 True\n",
      "Equal 1 False\n",
      "Equal 2 True\n",
      "Equal 3 False\n",
      "Equal 4 True\n",
      "Equal 5 False\n",
      "Equal 6 True\n",
      "Equal 7 False\n",
      "Equal 8 True\n",
      "Equal 9 False\n",
      "Equal 10 True\n",
      "Equal 11 False\n",
      "Equal 12 True\n",
      "Equal 13 False\n",
      "Equal 14 True\n",
      "Equal 15 False\n",
      "Equal 16 True\n",
      "Equal 17 False\n",
      "Equal 18 True\n",
      "Equal 19 False\n",
      "Equal 20 True\n",
      "Equal 21 False\n",
      "Equal 22 True\n",
      "Equal 23 False\n",
      "Equal 24 True\n",
      "Equal 25 False\n",
      "Equal 26 True\n",
      "Equal 27 False\n",
      "Equal 28 True\n",
      "Equal 29 False\n",
      "Equal 30 True\n",
      "Equal 31 False\n",
      "Equal 32 True\n",
      "Equal 33 False\n",
      "Equal 34 True\n",
      "Equal 35 False\n",
      "Equal 36 True\n",
      "Equal 37 False\n",
      "Equal 38 True\n",
      "Equal 39 False\n",
      "Equal 40 True\n",
      "Equal 41 False\n",
      "Equal 42 True\n",
      "Equal 43 False\n",
      "Equal 44 True\n",
      "Equal 45 False\n",
      "Equal 46 True\n",
      "Equal 47 False\n",
      "Equal 48 True\n",
      "Equal 49 False\n",
      "Equal 50 True\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 51, 1):\n",
    "    print(f\"Equal {i}\", all([x['conversation_a'][i] == x['conversation_b'][i] if len(x['conversation_a']) > i else True for x in data ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_reranker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
