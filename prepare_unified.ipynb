{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train\n",
      "Loaded #160800 from hh_rlhf\n",
      "Loaded #92858 from summary_from_feedback\n",
      "Loaded #19578 from webgpt\n",
      "Loaded #33143 from synthetic-instruct-gptj-pairwise\n",
      "Loaded #29481 from chatbot_arena_conv\n",
      "Loaded #59917 from ultra_feedback_clean\n",
      "Loaded #364908 from nectar\n",
      "Loading val\n",
      "Loaded #3276 from chatbot_arena_conv\n",
      "Loaded #1000 from ultra_feedback_clean\n",
      "Loaded #1000 from nectar\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "random.seed(42)\n",
    "from itertools import combinations\n",
    "mix_datasets = ['hh_rlhf', \"summary_from_feedback\", \"webgpt\", \"synthetic-instruct-gptj-pairwise\", \"chatbot_arena_conv\", \"ultra_feedback_clean\", \"nectar\"]\n",
    "data_dir = Path(\"./sub_datasets\")\n",
    "unified_data = {}\n",
    "for set_name in ['train', 'val']:\n",
    "    total_data = []\n",
    "    print(f\"Loading {set_name}\")\n",
    "    for dataset in mix_datasets:\n",
    "        file_name = data_dir / dataset / f\"{set_name}_data_prepared.json\"\n",
    "        if not file_name.exists():\n",
    "            continue\n",
    "        with open(file_name, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            print(f\"Loaded #{len(data)} from {dataset}\")\n",
    "            total_data += data\n",
    "    unified_data[set_name] = total_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(unified_data['train'])\n",
    "\n",
    "unified_data['val'] += unified_data['train'][-5000:]\n",
    "unified_data['train'] = unified_data['train'][:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved #755685 at train_data_unified.json\n",
      "Saved #10276 at val_data_unified.json\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "for set_name in unified_data:\n",
    "    with open(f\"./{set_name}_data_unified.json\", \"w\") as f:\n",
    "        json.dump(unified_data[set_name], f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Saved #{len(unified_data[set_name])} at {set_name}_data_unified.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release binary data\n",
    "import json\n",
    "import os\n",
    "set_name = \"train\"\n",
    "file = f\"./{set_name}_data_unified.json\"\n",
    "\n",
    "with open(file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "release_data = []\n",
    "for item in data:\n",
    "    candidates = item[\"candidates\"]\n",
    "    cand1_text = candidates[0][\"text\"]\n",
    "    cand2_text = candidates[1][\"text\"]\n",
    "    cand1_rating = candidates[0][\"scores\"][\"human_preference\"]\n",
    "    cand2_rating = candidates[1][\"scores\"][\"human_preference\"]\n",
    "    if \"model\" not in candidates[0]:\n",
    "        print(item)\n",
    "        break\n",
    "    cand1_model = candidates[0][\"model\"]\n",
    "    cand2_model = candidates[1][\"model\"]\n",
    "    if cand1_rating > cand2_rating:\n",
    "        chosen_text = cand1_text\n",
    "        chosen_model = cand1_model\n",
    "        chosen_rating = cand1_rating\n",
    "        rejected_text = cand2_text\n",
    "        rejected_model = cand2_model\n",
    "        rejected_rating = cand2_rating\n",
    "    else:\n",
    "        chosen_text = cand2_text\n",
    "        chosen_model = cand2_model\n",
    "        chosen_rating = cand2_rating\n",
    "        rejected_text = cand1_text\n",
    "        rejected_model = cand1_model\n",
    "        rejected_rating = cand1_rating\n",
    "    \n",
    "    release_item = {\n",
    "        \"id\": item[\"id\"],\n",
    "        \"prompt\": item[\"instruction\"] + \"\\n\" + item[\"input\"],\n",
    "        \"chosen_text\": chosen_text,\n",
    "        \"chosen_model\": chosen_model,\n",
    "        \"chosen_rating\": chosen_rating,\n",
    "        \"rejected_text\": rejected_text,\n",
    "        \"rejected_model\": rejected_model,\n",
    "        \"rejected_rating\": rejected_rating\n",
    "    }\n",
    "    release_data.append(release_item)\n",
    "with open(f\"{set_name}_unified_release_data.json\", 'w') as f:\n",
    "    json.dump(release_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_reranker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
