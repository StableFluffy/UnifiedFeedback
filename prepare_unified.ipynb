{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train\n",
      "Loaded #160800 from hh_rlhf\n",
      "Loaded #92858 from summary_from_feedback\n",
      "Loaded #19578 from webgpt\n",
      "Loaded #33143 from synthetic-instruct-gptj-pairwise\n",
      "Loaded #29481 from chatbot_arena_conv\n",
      "Loaded #59917 from ultra_feedback_clean\n",
      "Loaded #364908 from nectar\n",
      "Loading val\n",
      "Loaded #3276 from chatbot_arena_conv\n",
      "Loaded #1000 from ultra_feedback_clean\n",
      "Loaded #1000 from nectar\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "random.seed(42)\n",
    "from itertools import combinations\n",
    "mix_datasets = ['hh_rlhf', \"summary_from_feedback\", \"webgpt\", \"synthetic-instruct-gptj-pairwise\", \"chatbot_arena_conv\", \"ultra_feedback_clean\", \"nectar\"]\n",
    "data_dir = Path(\"./sub_datasets\")\n",
    "unified_data = {}\n",
    "for set_name in ['train', 'val']:\n",
    "    total_data = []\n",
    "    print(f\"Loading {set_name}\")\n",
    "    for dataset in mix_datasets:\n",
    "        file_name = data_dir / dataset / f\"{set_name}_data_prepared.json\"\n",
    "        if not file_name.exists():\n",
    "            continue\n",
    "        with open(file_name, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            for item in data:\n",
    "                item['source'] = dataset\n",
    "            print(f\"Loaded #{len(data)} from {dataset}\")\n",
    "            total_data += data\n",
    "    unified_data[set_name] = total_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'synthetic-instruct-gptj-pairwise-22479',\n",
       " 'instruction': 'What is the average life expectancy of a rabbit.',\n",
       " 'input': '',\n",
       " 'candidates': [{'text': 'The average life expectancy of a rabbit is between 8 and 12 years.',\n",
       "   'model': 'unknown',\n",
       "   'decoding_method': 'unknown',\n",
       "   'scores': {'human_preference': 1}},\n",
       "  {'text': 'Thereâ€™s a lot of variability.  Right now, the average is 69 years, but it was in a 1965 article, put at 87 years.  These are just numbers, however.',\n",
       "   'model': 'unknown',\n",
       "   'decoding_method': 'unknown',\n",
       "   'scores': {'human_preference': 0}}],\n",
       " 'source': 'synthetic-instruct-gptj-pairwise'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(unified_data['train'])\n",
    "\n",
    "unified_data['val'] += unified_data['train'][-5000:]\n",
    "unified_data['train'] = unified_data['train'][:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved #755685 at train_data_unified.json\n",
      "Saved #10276 at val_data_unified.json\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "for set_name in unified_data:\n",
    "    with open(f\"./{set_name}_data_unified.json\", \"w\") as f:\n",
    "        json.dump(unified_data[set_name], f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Saved #{len(unified_data[set_name])} at {set_name}_data_unified.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2011a4c56d4a1d8f373c60408dc751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_unified_release_data.json:   0%|          | 0.00/2.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/datasets/llm-blender/Unified-Feedback/blob/main/datasets/unified/train_release_data.json'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# release binary data\n",
    "import json\n",
    "import os\n",
    "set_name = \"train\"\n",
    "file = f\"./{set_name}_data_unified.json\"\n",
    "\n",
    "with open(file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "release_data = []\n",
    "for item in data:\n",
    "    candidates = item[\"candidates\"]\n",
    "    cand1_text = candidates[0][\"text\"]\n",
    "    cand2_text = candidates[1][\"text\"]\n",
    "    cand1_rating = candidates[0][\"scores\"][\"human_preference\"]\n",
    "    cand2_rating = candidates[1][\"scores\"][\"human_preference\"]\n",
    "    if \"model\" not in candidates[0]:\n",
    "        print(item)\n",
    "        break\n",
    "    cand1_model = candidates[0][\"model\"]\n",
    "    cand2_model = candidates[1][\"model\"]\n",
    "    if cand1_rating > cand2_rating:\n",
    "        chosen_text = cand1_text\n",
    "        chosen_model = cand1_model\n",
    "        chosen_rating = cand1_rating\n",
    "        rejected_text = cand2_text\n",
    "        rejected_model = cand2_model\n",
    "        rejected_rating = cand2_rating\n",
    "    else:\n",
    "        chosen_text = cand2_text\n",
    "        chosen_model = cand2_model\n",
    "        chosen_rating = cand2_rating\n",
    "        rejected_text = cand1_text\n",
    "        rejected_model = cand1_model\n",
    "        rejected_rating = cand1_rating\n",
    "    \n",
    "    release_item = {\n",
    "        \"id\": item[\"id\"],\n",
    "        \"prompt\": item[\"instruction\"] + \"\\n\" + item[\"input\"],\n",
    "        \"chosen_text\": chosen_text,\n",
    "        \"chosen_model\": chosen_model,\n",
    "        \"chosen_rating\": chosen_rating,\n",
    "        \"rejected_text\": rejected_text,\n",
    "        \"rejected_model\": rejected_model,\n",
    "        \"rejected_rating\": rejected_rating,\n",
    "        \"source\": item[\"source\"]\n",
    "    }\n",
    "    release_data.append(release_item)\n",
    "with open(f\"{set_name}_unified_release_data.json\", 'w') as f:\n",
    "    json.dump(release_data, f, indent=4)\n",
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "        path_or_fileobj=f\"{set_name}_unified_release_data.json\",\n",
    "        path_in_repo=f\"datasets/unified/{set_name}_release_data.json\",\n",
    "        repo_id=\"llm-blender/Unified-Feedback\",\n",
    "        repo_type=\"dataset\",\n",
    "        token=os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c95f534e6f349378002987e0771bcc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_synthetic-instruct-gptj-pairwise_release_data.json:   0%|          | 0.00/40.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa5cf2499e144d9bd2f9ab116d5a664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_nectar_release_data.json:   0%|          | 0.00/929M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d80d051fd648269d44716ad8de4873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_hh_rlhf_release_data.json:   0%|          | 0.00/637M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebc21f108c14872af571e2205f2b12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_ultra_feedback_clean_release_data.json:   0%|          | 0.00/214M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6c290fc9c045df871d71ab4d3e84c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_summary_from_feedback_release_data.json:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78a93b1b2a6491181a44eb68b4c88db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_chatbot_arena_conv_release_data.json:   0%|          | 0.00/71.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80674c651de340db8179cfd3d1260b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_webgpt_release_data.json:   0%|          | 0.00/37.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import HfApi\n",
    "from collections import defaultdict\n",
    "api = HfApi()\n",
    "sources = set([item[\"source\"] for item in release_data])\n",
    "\n",
    "data_map = {}\n",
    "set_name = \"train\"\n",
    "with open(f\"{set_name}_unified_release_data.json\", 'r') as f:\n",
    "    release_data = json.load(f)\n",
    "for item in release_data:\n",
    "    if item[\"source\"] not in data_map:\n",
    "        data_map[item[\"source\"]] = []\n",
    "    else:\n",
    "        data_map[item[\"source\"]].append(item)\n",
    "\n",
    "for source in data_map:\n",
    "    with open(f\"{set_name}_{source}_release_data.json\", 'w') as f:\n",
    "        json.dump(data_map[source], f, indent=2)\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=f\"{set_name}_{source}_release_data.json\",\n",
    "        path_in_repo=f\"datasets/{source}/{set_name}_release_data.json\",\n",
    "        repo_id=\"llm-blender/Unified-Feedback\",\n",
    "        repo_type=\"dataset\",\n",
    "        token=os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = defaultdict(defaultdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_reranker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
